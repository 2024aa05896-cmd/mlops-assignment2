{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CFptP-qWZs8Ozhr1XQ0igmiabJFGO5qL",
      "authorship_tag": "ABX9TyNsX9+2nYYLhDe1Ur1BSV3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2024aa05896-cmd/mlops-assignment2/blob/main/cats%26dogsclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLOPS - Group 40**\n",
        "\n",
        "* ANIL PRASAD CHELAMCHELA - 2024AA05896 - 100%\n",
        "* YALLA SIREESHA - 2024AA05728 - 100%\n",
        "* DIKSHA GUPTA - 2024AA05518 - 100%\n",
        "* SUVITHA J - 2024AA05756 - 100%\n",
        "* VINAYAK BAJORIA - 2024AA05493 - 100%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EwbKJi3ItoIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1\n",
        "**Binary image classification (Cats vs Dogs) for a pet adoption platform.**\n",
        "\n",
        "\n",
        "**Pre-processing**\n",
        "\n",
        "In this we would do the following:\n",
        "* conver the images to 224x224 input size for processing into ResNet, VGG or DenseNet\n",
        "* 3 channel RGB will make pretrained CNN into 3 channels\n",
        "* All images would be in same consistent size of 224x224, 3 channels\n",
        "\n",
        "**Data Splitting**\n",
        "\n",
        "* Train - 80%\n",
        "* Validation - 10%\n",
        "* Test sets 10%\n",
        "\n",
        "Use data augmentation for better generalization\n",
        "\n"
      ],
      "metadata": {
        "id": "CIjjzin1uLh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8YLcF7ui9XS",
        "outputId": "faea4b3f-9219-478b-a98d-29ec06ad8dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa4HgBIetmIi",
        "outputId": "4c221f73-7a86-43dd-c5c7-f686709b70d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4838 images belonging to 4 classes.\n",
            "Found 604 images belonging to 4 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Class labels: {'.ipynb_checkpoints': 0, 'Cat': 1, 'Dog': 2, 'petimages_test': 3}\n",
            "Image batch shape: (32, 224, 224, 3)\n",
            "Label batch shape: (32,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Variable Declarations\n",
        "\n",
        "IMG_DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/ML Ops/PetImages\"\n",
        "IMG_TARGET_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "# Train - 80% Validation (80% + 10%)\n",
        "\n",
        "# Hence validation split = 0.1111 because: 10% / (80% + 10%) = 0.1111\n",
        "\n",
        "\n",
        "train_val_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        "    validation_split=0.1111\n",
        ")\n",
        "\n",
        "train_generator = train_val_datagen.flow_from_directory(\n",
        "    directory=IMG_DATA_DIR,\n",
        "    target_size=IMG_TARGET_SIZE,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_generator = train_val_datagen.flow_from_directory(\n",
        "    directory=IMG_DATA_DIR,\n",
        "    target_size=IMG_TARGET_SIZE,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"validation\",\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Preparing 10% as test set\n",
        "# Will move test set to a separate folder.\n",
        "\n",
        "TEST_DIR = \"/content/drive/MyDrive/Colab Notebooks/ML Ops/PetImages/petimages_test\"  # create this with cats/ and dogs/\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=TEST_DIR,\n",
        "    target_size=IMG_TARGET_SIZE,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Preprocess check\n",
        "print(\"Class labels:\", train_generator.class_indices)\n",
        "\n",
        "x_batch, y_batch = next(train_generator)\n",
        "print(\"Image batch shape:\", x_batch.shape)  # (32, 224, 224, 3)\n",
        "print(\"Label batch shape:\", y_batch.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2\n",
        "**M1: Model Development & Experiment Tracking**\n",
        "\n",
        "**Data & Code Versioning**\n",
        "\n",
        "* Version is needed to keep track of changes in data and code as well.\n",
        "* This would also enable collaboration among team members and help in managing releases.\n",
        "* Versioning would also help in rolling back in case of any issues.\n",
        "\n",
        "WIll use github for versioning\n"
      ],
      "metadata": {
        "id": "1Qa7PMagg1-b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xj5aFaCCtn8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}